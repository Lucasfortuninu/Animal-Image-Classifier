{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3da1e564",
   "metadata": {},
   "source": [
    "# <font color='red'>1. Implementacion los algoritmos de extraccion de caracteristicas.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750aefd4",
   "metadata": {},
   "source": [
    "### Algortimo de extraccion de caractristicas 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c072d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2deb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraccionCaracteristicas1(imagen, N):\n",
    "    \n",
    "    # Como son 8 vecinos sin contar el pixel central, la ventana debe ser de 3*3\n",
    "    tamVentana = 3\n",
    "    mitad = tamVentana // 2 \n",
    "    alto = imagen.shape[0]\n",
    "    ancho = imagen.shape[1]\n",
    "    vector_caracteristicas = []\n",
    "    \n",
    "    # Recorro imagen para crear celdas\n",
    "    for i in range(0, alto - N + 1, N):  \n",
    "        for j in range(0, ancho - N + 1, N):\n",
    "            celda = imagen[i:i+N, j:j+N]\n",
    "            celdaAmpliada = cv2.copyMakeBorder(celda, mitad, mitad, mitad, mitad, cv2.BORDER_REPLICATE)\n",
    "            histograma_celda = []\n",
    "            transiciones_no_uniformes = 0  \n",
    "            \n",
    "            # Recorro celdas para crear vetana de vecinos\n",
    "            for fil in range(1, N + mitad):\n",
    "                for col in range(1, N + mitad):\n",
    "                    ventana = celdaAmpliada[fil-mitad:fil+mitad+1, col-mitad:col+mitad+1]\n",
    "                    pixelCentral = ventana[mitad, mitad]\n",
    "                    numeros_binarios = []\n",
    "                    \n",
    "                    # Recorro ventana para crear el numeor binario\n",
    "                    for filVecino in range(len(ventana)):\n",
    "                        for colVecino in range(len(ventana)):\n",
    "                            vecino = ventana[filVecino][colVecino]\n",
    "                            \n",
    "                            # Si no es el pixel central\n",
    "                            if filVecino != mitad or colVecino != mitad:\n",
    "                                if vecino < pixelCentral:\n",
    "                                    numeros_binarios.append(0)\n",
    "                                else:\n",
    "                                    numeros_binarios.append(1)\n",
    "                                    \n",
    "                    # Convierto el nuemero binario a decimal\n",
    "                    numero_decimal = sum(bit << idx for idx, bit in enumerate(reversed(numeros_binarios)))\n",
    "                    #celda[fil-mitad, col-mitad] = numero_decimal\n",
    "                    \n",
    "                    # Cuento transiciones no uniformes\n",
    "                    transiciones = sum(abs(numeros_binarios[i]-numeros_binarios[i-1]) for i in range(1,8))\n",
    "                    transiciones += abs(numeros_binarios[7]-numeros_binarios[0])\n",
    "                    if transiciones > 2:\n",
    "                        transiciones_no_uniformes += 1\n",
    "                    histograma_celda.append(numero_decimal if transiciones <= 2 else 58)\n",
    "                    \n",
    "            # 60 bins para valores entre 0 y 59\n",
    "            histograma, _ = np.histogram(histograma_celda, bins=range(60))\n",
    "            \n",
    "            # Concateno histogramas\n",
    "            vector_caracteristicas.extend(histograma)\n",
    "            \n",
    "    #print(len(vector_caracteristicas)) \n",
    "    \n",
    "    return vector_caracteristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6216c4",
   "metadata": {},
   "source": [
    "### Algortimo de extraccion de caractristicas 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f3374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraccionCaracteristicas2(imagen, N, M):\n",
    "    alto = imagen.shape[0]\n",
    "    ancho = imagen.shape[1]\n",
    "    histogramas = []\n",
    "    \n",
    "    mascara_x = np.array([[-1], [0], [1]])\n",
    "    mascara_y = np.array([[-1, 0, 1]])\n",
    "    \n",
    "    # Convolucion mascaras derivada\n",
    "    gradiente_x = filtro(imagen, mascara_x)\n",
    "    gradiente_y = filtro(imagen, mascara_y)\n",
    "\n",
    "    magnitud = np.sqrt(gradiente_x**2 + gradiente_y**2)\n",
    "    orientacion = np.rad2deg(np.arctan2(gradiente_y, gradiente_x)) % 180\n",
    "\n",
    "    bloques = []\n",
    "    vector_caracteristicas = []\n",
    "    \n",
    "    # Recorro imagen para crear celdas\n",
    "    for i in range(0, alto - N + 1, N): \n",
    "        for j in range(0, ancho - N + 1, N):\n",
    "            celda = imagen[i:i+N, j:j+N]\n",
    "            histograma = np.zeros(9)\n",
    "            \n",
    "            # Recorro celdas para construir los histogramas de cada celda\n",
    "            for fil in range(N):\n",
    "                for col in range(N):\n",
    "                    bin_indice = int(orientacion[i + fil, j + col] % 180 // 20)\n",
    "                    histograma[bin_indice] += magnitud[i + fil, j + col]\n",
    "            histogramas.append(histograma)\n",
    "\n",
    "    # Convierto la lista de histogramas en un array de NumPy\n",
    "    histogramas = np.array(histogramas).reshape(alto//N, ancho//N, -1)\n",
    "\n",
    "    # Normalizo los histogramas de los bloques\n",
    "    for i in range(0, alto//N - M + 1): \n",
    "        for j in range(0, ancho//N - M + 1):\n",
    "            bloque = histogramas[i:i+M, j:j+M]\n",
    "            bloque = bloque.reshape(-1)  # Convierto el bloque a un vector unidimensional\n",
    "            norma = np.linalg.norm(bloque)\n",
    "            bloque = bloque / norma if norma != 0 else bloque  # Normalizo el bloque\n",
    "            vector_caracteristicas.extend(bloque)\n",
    "            \n",
    "    #print(len(vector_caracteristicas))\n",
    "    \n",
    "    return vector_caracteristicas\n",
    "\n",
    "def filtro(imagen, mascara):\n",
    "    imagen_f = np.zeros(imagen.shape)\n",
    "    altura, anchura = imagen.shape\n",
    "    mitad = 3//2 \n",
    "    imagenAmpliada = cv2.copyMakeBorder(imagen, mitad, mitad, mitad, mitad, cv2.BORDER_REPLICATE)\n",
    "    for i in range(mitad, altura + mitad):\n",
    "        for j in range(mitad, anchura + mitad):\n",
    "            region = imagenAmpliada[i - mitad : i + mitad + 1, j - mitad : j + mitad + 1]\n",
    "            convolucion = np.sum(np.multiply(mascara, region))\n",
    "            imagen_f[i - mitad, j - mitad] = convolucion\n",
    "    return imagen_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aa10ef",
   "metadata": {},
   "source": [
    "# <font color='red'>2. Cargado de el conjunto de datos.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "\n",
    "def cargar_imagenes(ruta_carpeta):\n",
    "    lista_imagenes = []\n",
    "    etiquetas = []\n",
    "    \n",
    "    # Recorro las carpetas en la ruta proporcionada\n",
    "    for raiz, directorios, archivos in os.walk(ruta_carpeta):\n",
    "        for nombre_directorio in directorios:\n",
    "            etiqueta = nombre_directorio  # El nombre de la carpeta es la etiqueta\n",
    "            ruta_etiqueta = os.path.join(ruta_carpeta, nombre_directorio)\n",
    "            \n",
    "            # Recorro los archivos dentro de cada carpeta (etiqueta)\n",
    "            for raiz2, directorios2, archivos2 in os.walk(ruta_etiqueta):\n",
    "                for nombre_archivo in archivos2:\n",
    "                    # Verfico si el archivo es una imagen\n",
    "                    if nombre_archivo.endswith(\".jpg\") or nombre_archivo.endswith(\".png\") or nombre_archivo.endswith(\".jpeg\"):\n",
    "                        ruta_imagen = os.path.join(raiz2, nombre_archivo)\n",
    "                        imagen = io.imread(ruta_imagen)\n",
    "                        lista_imagenes.append(imagen)\n",
    "                        etiquetas.append(etiqueta)\n",
    "    \n",
    "    return lista_imagenes, etiquetas\n",
    "\n",
    "\n",
    "carpeta_entrenamiento = 'dataset/train_500'\n",
    "carpeta_validacion = 'dataset/train_100'\n",
    "carpeta_prueba = 'dataset/test'\n",
    "\n",
    "imagenes_entrenamiento, etiquetas_entrenamiento = cargar_imagenes(carpeta_entrenamiento)\n",
    "imagenes_validacion, etiquetas_validacion = cargar_imagenes(carpeta_validacion)\n",
    "imagenes_prueba, etiquetas_prueba = cargar_imagenes(carpeta_prueba)\n",
    "\n",
    "# Junto conjuntos de entrenamiento y validaci칩n ya que gridsearch hara la validacion cruzada\n",
    "imagenes_entrenamiento.extend(imagenes_validacion)\n",
    "etiquetas_entrenamiento.extend(etiquetas_validacion)\n",
    "\n",
    "cantidad_imagenes_entrenamiento = len(imagenes_entrenamiento)\n",
    "cantidad_imagenes_prueba = len(imagenes_prueba)\n",
    "\n",
    "print(f\"Recuento de im치genes en el conjunto de entrenamiento: {cantidad_imagenes_entrenamiento}\")\n",
    "print(f\"Recuento de im치genes en el conjunto de prueba: {cantidad_imagenes_prueba}\")\n",
    "\n",
    "# Imprimo la primera imagen y su etiqueta del conjunto de entrenamiento\n",
    "if len(imagenes_entrenamiento) > 0:\n",
    "    print(\"Etiqueta:\", etiquetas_entrenamiento[0])\n",
    "    io.imshow(imagenes_entrenamiento[0])\n",
    "    io.show()\n",
    "else:\n",
    "    print(\"No se encontraron im치genes de entrenamiento.\")\n",
    "\n",
    "# Imprimo la primera imagen y su etiqueta del conjunto de prueba\n",
    "if len(imagenes_prueba) > 0:\n",
    "    print(\"Etiqueta:\", etiquetas_prueba[0])\n",
    "    io.imshow(imagenes_prueba[0])\n",
    "    io.show()\n",
    "else:\n",
    "    print(\"No se encontraron im치genes de prueba.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87ebdf",
   "metadata": {},
   "source": [
    "# <font color='red'>3. Preprocesamiento de los conjuntos de imagenes.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea18360",
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "from skimage import transform, color\n",
    "\n",
    "def preprocesar_imagenes(imagenes, nuevo_tama침o=(128, 128)):\n",
    "    imagenes_preprocesadas = []\n",
    "    contador = 0\n",
    "    for img in imagenes:\n",
    "        img_gris = color.rgb2gray(img)\n",
    "        img_redimensionada = transform.resize(img_gris, nuevo_tama침o)\n",
    "        imagenes_preprocesadas.append(img_redimensionada)\n",
    "        if contador is not None:\n",
    "            print(f\"Imagen procesada {contador}\")\n",
    "            contador += 1\n",
    "    return imagenes_preprocesadas\n",
    "\n",
    "# Preprocesamiento de las im치genes de entrenamiento\n",
    "imagenes_entrenamiento_procesadas = preprocesar_imagenes(imagenes_entrenamiento)\n",
    "\n",
    "# Preprocesamiento de las im치genes de prueba\n",
    "imagenes_prueba_procesadas = preprocesar_imagenes(imagenes_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimo la primera imagen y su etiqueta del conjunto de entrenamiento\n",
    "if len(imagenes_entrenamiento_procesadas) > 0:\n",
    "    print(\"Etiqueta:\", etiquetas_entrenamiento[0])\n",
    "    io.imshow(imagenes_entrenamiento_procesadas[0])\n",
    "    io.show()\n",
    "else:\n",
    "    print(\"No se encontraron im치genes de entrenamiento.\")\n",
    "     \n",
    "# Imprimo la primera imagen y su etiqueta del conjunto de test\n",
    "if len(imagenes_prueba_procesadas) > 0:\n",
    "    print(\"Etiqueta:\", etiquetas_prueba[0])\n",
    "    io.imshow(imagenes_prueba_procesadas[0])\n",
    "    io.show()\n",
    "else:\n",
    "    print(\"No se encontraron im치genes de test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e685a2f",
   "metadata": {},
   "source": [
    "# <font color='red'>4. Extraccion de caracteristicas de los conjuntos de datos.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e361f4d2",
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "def extraer_caracteristicas(imagenes_procesadas, caracteristicasV1, caracteristicasV2, N=16, M=2, tipo=\"\"):\n",
    "    counter = 0\n",
    "    print(f\"Procesando im치genes {tipo}...\")\n",
    "    for img in imagenes_procesadas:\n",
    "        \n",
    "        # Extraccion de caracteristicas mediante el algoritmo 1\n",
    "        caracteristicas_V1 = extraccionCaracteristicas1(img, N=N)\n",
    "        \n",
    "        # Extraccion de caracteristicas mediante el algoritmo 2\n",
    "        caracteristicas_V2 = extraccionCaracteristicas2(img, N=N, M=M)\n",
    "        \n",
    "        caracteristicasV1.append(caracteristicas_V1)\n",
    "        caracteristicasV2.append(caracteristicas_V2)\n",
    "        if counter is not None:\n",
    "            print(f\"Imagen {tipo} procesada {counter}\")\n",
    "            counter += 1\n",
    "\n",
    "# Llamo a la funci칩n para las im치genes de entrenamiento\n",
    "caracteristicas_entrenamientoV1 = []\n",
    "caracteristicas_entrenamientoV2 = []\n",
    "extraer_caracteristicas(imagenes_entrenamiento_procesadas, caracteristicas_entrenamientoV1, caracteristicas_entrenamientoV2, tipo=\"de entrenamiento\")\n",
    "\n",
    "# Llamo a la funci칩n para las im치genes de prueba\n",
    "caracteristicas_pruebaV1 = []\n",
    "caracteristicas_pruebaV2 = []\n",
    "extraer_caracteristicas(imagenes_prueba_procesadas, caracteristicas_pruebaV1, caracteristicas_pruebaV2, tipo=\"de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f5b71",
   "metadata": {},
   "source": [
    "# <font color='red'>5. Implementacion de los modelos.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a233d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convierto las  listas de caracter칤sticas y etiquetas a matrices numpy para el entrenamiento de los modelos\n",
    "X_entrenamientoV1 = np.array(caracteristicas_entrenamientoV1)\n",
    "X_pruebaV1 = np.array(caracteristicas_pruebaV1)\n",
    "X_entrenamientoV2 = np.array(caracteristicas_entrenamientoV2)\n",
    "X_pruebaV2 = np.array(caracteristicas_pruebaV2)\n",
    "y_entrenamiento = np.array(etiquetas_entrenamiento)\n",
    "y_prueba = np.array(etiquetas_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812b3f00",
   "metadata": {},
   "source": [
    "### Modelo 1: SVM (Support vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Creo los clasificadores SVM\n",
    "clfV1 = svm.SVC(kernel='linear')\n",
    "clfV2 = svm.SVC(kernel='linear')\n",
    "\n",
    "# Defino los par치metros a ajustar\n",
    "parametros_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1 = GridSearchCV(clfV1, parametros_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV1.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2 = GridSearchCV(clfV2, parametros_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV2.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtengo los mejores clasificadores y sus par치metros\n",
    "best_clfV1 = grid_searchV1.best_estimator_\n",
    "best_paramsV1 = grid_searchV1.best_params_\n",
    "\n",
    "best_clfV2 = grid_searchV2.best_estimator_\n",
    "best_paramsV2 = grid_searchV2.best_params_\n",
    "\n",
    "# Realizo predicciones en los conjuntos de prueba con los mejores clasificadores\n",
    "prediccionesV1 = best_clfV1.predict(X_pruebaV1)\n",
    "prediccionesV2 = best_clfV2.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "precisionV1 = accuracy_score(y_prueba, prediccionesV1)\n",
    "precisionV2 = accuracy_score(y_prueba, prediccionesV2)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Mejores par치metros para V1:\", best_paramsV1)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1.best_score_)\n",
    "print(\"Rendimiento de test V1:\", precisionV1)\n",
    "\n",
    "print(\"Mejores par치metros para V2:\", best_paramsV2)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2.best_score_)\n",
    "print(\"Rendimiento de test V2:\", precisionV2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00726c5",
   "metadata": {},
   "source": [
    "### Modelo 2: Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Par치metros para la b칰squeda de la mejor C en la regresi칩n log칤stica\n",
    "param_grid_logistic = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Creo el modelo de regresi칩n log칤stica\n",
    "logistic_clfV1 = LogisticRegression(max_iter = 1000)\n",
    "logistic_clfV2 = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1_train_logistic = GridSearchCV(logistic_clfV1, param_grid_logistic, cv=5, scoring='accuracy')\n",
    "grid_searchV1_train_logistic.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2_train_logistic = GridSearchCV(logistic_clfV2, param_grid_logistic, cv=5, scoring='accuracy')\n",
    "grid_searchV2_train_logistic.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtengo el mejor clasificador\n",
    "best_logistic_clfV1_train = grid_searchV1_train_logistic.best_estimator_\n",
    "best_logistic_clfV2_train = grid_searchV2_train_logistic.best_estimator_\n",
    "\n",
    "# Realizo predicciones en el conjunto de prueba\n",
    "predictionsV1_test_logistic = best_logistic_clfV1_train.predict(X_pruebaV1)\n",
    "predictionsV2_test_logistic = best_logistic_clfV2_train.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "accuracyV1_test_logistic = accuracy_score(y_prueba, predictionsV1_test_logistic)\n",
    "accuracyV2_test_logistic = accuracy_score(y_prueba, predictionsV2_test_logistic)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Mejor C V1:\", best_logistic_clfV1_train.C)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1_train_logistic.best_score_)\n",
    "print(\"Rendimiento de test V1:\", accuracyV1_test_logistic)\n",
    "\n",
    "print(\"Mejor C V2:\", best_logistic_clfV2_train.C)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2_train_logistic.best_score_)\n",
    "print(\"Rendimiento de test V2:\", accuracyV2_test_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57553ff0",
   "metadata": {},
   "source": [
    "### Modelo 3: Regresion logistica con caracteristicas polinimicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63507809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Defino el rango de grados a probar\n",
    "degrees = [1, 2, 3]\n",
    "\n",
    "# Par치metros para la b칰squeda de la mejor C y grado en la regresi칩n log칤stica polin칩mica\n",
    "param_grid_logistic_poly = {'polynomialfeatures__degree': degrees, 'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Creo el modelo de regresi칩n log칤stica con caracter칤sticas polin칩micas\n",
    "logistic_clfV1_poly = make_pipeline(PolynomialFeatures(), LogisticRegression(max_iter = 1000))\n",
    "logistic_clfV2_poly = make_pipeline(PolynomialFeatures(), LogisticRegression(max_iter = 1000))\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1_train_logistic_poly = GridSearchCV(logistic_clfV1_poly, param_grid_logistic_poly, cv=5, scoring='accuracy')\n",
    "grid_searchV1_train_logistic_poly.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2_train_logistic_poly = GridSearchCV(logistic_clfV2_poly, param_grid_logistic_poly, cv=5, scoring='accuracy')\n",
    "grid_searchV2_train_logistic_poly.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtener el mejor clasificador\n",
    "best_logistic_clfV1_train_poly = grid_searchV1_train_logistic_poly.best_estimator_\n",
    "best_logistic_clfV2_train_poly = grid_searchV2_train_logistic_poly.best_estimator_\n",
    "\n",
    "# Realizo predicciones en el conjunto de prueba con los mejores clasificadores\n",
    "predictionsV1_test_logistic_poly = best_logistic_clfV1_train_poly.predict(X_pruebaV1)\n",
    "predictionsV2_test_logistic_poly = best_logistic_clfV2_train_poly.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "accuracyV1_test_logistic_poly = accuracy_score(y_prueba, predictionsV1_test_logistic_poly)\n",
    "accuracyV2_test_logistic_poly = accuracy_score(y_prueba, predictionsV2_test_logistic_poly)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Mejor grado V1:\", best_logistic_clfV1_train_poly.named_steps['polynomialfeatures'].degree)\n",
    "print(\"Mejor C V1 (con caracter칤sticas polin칩micas):\", best_logistic_clfV1_train_poly.named_steps['logisticregression'].C)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1_train_logistic_poly.best_score_)\n",
    "print(\"Rendimiento de test V1:\", accuracyV1_test_logistic_poly)\n",
    "\n",
    "print(\"Mejor grado V2:\", best_logistic_clfV2_train_poly.named_steps['polynomialfeatures'].degree)\n",
    "print(\"Mejor C V2 (con caracter칤sticas polin칩micas):\", best_logistic_clfV2_train_poly.named_steps['logisticregression'].C)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2_train_logistic_poly.best_score_)\n",
    "print(\"Rendimiento de test V2:\", accuracyV2_test_logistic_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb1728",
   "metadata": {},
   "source": [
    "### Modelo 4: Redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Creo el clasificador de red neuronal\n",
    "mlp = MLPClassifier(max_iter = 1000)\n",
    "\n",
    "# Defino los par치metros a ajustar\n",
    "parametros_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50)],\n",
    "}\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1 = GridSearchCV(mlp, parametros_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV1.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2 = GridSearchCV(mlp, parametros_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV2.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtengo el mejor clasificador y sus par치metros para V1\n",
    "best_mlpV1 = grid_searchV1.best_estimator_\n",
    "best_paramsV1 = grid_searchV1.best_params_\n",
    "\n",
    "# Obtengo el mejor clasificador y sus par치metros para V2\n",
    "best_mlpV2 = grid_searchV2.best_estimator_\n",
    "best_paramsV2 = grid_searchV2.best_params_\n",
    "\n",
    "# Realizo predicciones en los conjuntos de prueba con los mejores clasificadores\n",
    "prediccionesV1 = best_mlpV1.predict(X_pruebaV1)\n",
    "prediccionesV2 = best_mlpV2.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "precisionV1 = accuracy_score(y_prueba, prediccionesV1)\n",
    "precisionV2 = accuracy_score(y_prueba, prediccionesV2)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Mejores par치metros para V1:\", best_paramsV1)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1.best_score_)\n",
    "print(\"Rendimiento de test V1:\", precisionV1)\n",
    "\n",
    "print(\"Mejores par치metros para V2:\", best_paramsV2)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2.best_score_)\n",
    "print(\"Rendimiento de test V2:\", precisionV2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1742367",
   "metadata": {},
   "source": [
    "### Modelo 5: Ensembles basados en variaci칩n de datos (Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Par치metros para la b칰squeda de el mejor numero de estimadores\n",
    "param_grid = {'n_estimators': [10, 50, 100]}\n",
    "\n",
    "# Creo el clasificador base (Decision Tree)\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Creo el modelo de BaggingClassifier con GridSearchCV para encontrar la mejor profundidad\n",
    "bagging_clfV1 = BaggingClassifier(base_estimator=base_classifier, random_state=42)\n",
    "bagging_clfV2 = BaggingClassifier(base_estimator=base_classifier, random_state=42)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1_train = GridSearchCV(bagging_clfV1, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV1_train.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2_train = GridSearchCV(bagging_clfV1, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV2_train.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtengo el mejor clasificador\n",
    "best_clfV1_train = grid_searchV1_train.best_estimator_\n",
    "best_clfV2_train = grid_searchV2_train.best_estimator_\n",
    "\n",
    "# Realizo predicciones en los conjuntos de prueba con los mejores clasificadores\n",
    "predictionsV1_test = best_clfV1_train.predict(X_pruebaV1)\n",
    "predictionsV2_test = best_clfV2_train.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "accuracyV1_test = accuracy_score(y_prueba, predictionsV1_test)\n",
    "accuracyV2_test = accuracy_score(y_prueba, predictionsV2_test)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Mejor configuraci칩n V1:\", grid_searchV1_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1_train.best_score_)\n",
    "print(\"Rendimiento de test V1:\", accuracyV1_test)\n",
    "\n",
    "print(\"Mejor configuraci칩n V2:\", grid_searchV1_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2_train.best_score_)\n",
    "print(\"Rendimiento de test V2:\", accuracyV2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8febb885",
   "metadata": {},
   "source": [
    "### Modelo 6: Ensembles basados en variaci칩n de datos (Boosting: Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63563d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Par치metros para la b칰squeda de el mejor numero de estimadores\n",
    "param_grid = {'n_estimators': [10, 50, 100]}\n",
    "\n",
    "# Creo el clasificador base (Decision Tree)\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Crear el modelo de AdaBoostClassifier con GridSearchCV para encontrar la mejor profundidad\n",
    "adaboost_clfV1 = AdaBoostClassifier(base_estimator=base_classifier, random_state=42)\n",
    "adaboost_clfV2 = AdaBoostClassifier(base_estimator=base_classifier, random_state=42)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1_train = GridSearchCV(adaboost_clfV1, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV1_train.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2_train = GridSearchCV(adaboost_clfV2, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV2_train.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtengo el mejor clasificador\n",
    "best_clfV1_train = grid_searchV1_train.best_estimator_\n",
    "best_clfV2_train = grid_searchV2_train.best_estimator_\n",
    "\n",
    "# Realizo predicciones en los conjuntos de prueba con los mejores clasificadores\n",
    "predictionsV1_test = best_clfV1_train.predict(X_pruebaV1)\n",
    "predictionsV2_test = best_clfV2_train.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "accuracyV1_test = accuracy_score(y_prueba, predictionsV1_test)\n",
    "accuracyV2_test = accuracy_score(y_prueba, predictionsV2_test)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Mejor configuraci칩n V1:\", grid_searchV1_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1_train.best_score_)\n",
    "print(\"Rendimiento de test V1:\", accuracyV1_test)\n",
    "\n",
    "print(\"Mejor configuraci칩n V2:\", grid_searchV1_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2_train.best_score_)\n",
    "print(\"Rendimiento de test V2:\", accuracyV2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1520ee",
   "metadata": {},
   "source": [
    "### Modelo 7: Ensembles basados en variaci칩n de datos (Random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976256ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Par치metros para la b칰squeda de el mejor numero de estimadores\n",
    "param_grid = {'n_estimators': [10, 50, 100]}\n",
    "\n",
    "# Crear el clasificador base (Random Forest)\n",
    "base_classifier = RandomForestClassifier()\n",
    "\n",
    "# Crear el modelo de RandomForestClassifier con GridSearchCV para encontrar la mejor configuraci칩n\n",
    "rf_clfV1 = RandomForestClassifier()\n",
    "rf_clfV2 = RandomForestClassifier()\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1_train = GridSearchCV(rf_clfV1, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV1_train.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2_train = GridSearchCV(rf_clfV2, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV2_train.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtengo el mejor clasificador\n",
    "best_clfV1_train = grid_searchV1_train.best_estimator_\n",
    "best_clfV2_train = grid_searchV2_train.best_estimator_\n",
    "\n",
    "# Realizo predicciones en el conjunto de prueba con los mejores clasificadores\n",
    "predictionsV1_test = best_clfV1_train.predict(X_pruebaV1)\n",
    "predictionsV2_test = best_clfV2_train.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "accuracyV1_test = accuracy_score(y_prueba, predictionsV1_test)\n",
    "accuracyV2_test = accuracy_score(y_prueba, predictionsV2_test)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Mejor configuraci칩n V1:\", grid_searchV1_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1_train.best_score_)\n",
    "print(\"Rendimiento de test V1:\", accuracyV1_test)\n",
    "\n",
    "print(\"Mejor configuraci칩n V2:\", grid_searchV2_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2_train.best_score_)\n",
    "print(\"Rendimiento de test V2:\", accuracyV2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83421dfb",
   "metadata": {},
   "source": [
    "### Modelo 8: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "# Creo el modelo de clasificador con GridSearchCV para encontrar la mejor configuraci칩n\n",
    "nb_clfV1 = GaussianNB()\n",
    "nb_clfV2 = GaussianNB()\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1_train = GridSearchCV(nb_clfV1, param_grid={}, cv=5, scoring='accuracy')\n",
    "grid_searchV1_train.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2_train = GridSearchCV(nb_clfV2, param_grid={}, cv=5, scoring='accuracy')\n",
    "grid_searchV2_train.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtengo el mejor clasificador\n",
    "best_clfV1_train = grid_searchV1_train.best_estimator_\n",
    "best_clfV2_train = grid_searchV2_train.best_estimator_\n",
    "\n",
    "# Realizo predicciones en el conjunto de prueba con los mejores clasificadores\n",
    "predictionsV1_test = best_clfV1_train.predict(X_pruebaV1)\n",
    "predictionsV2_test = best_clfV2_train.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "accuracyV1_test = accuracy_score(y_prueba, predictionsV1_test)\n",
    "accuracyV2_test = accuracy_score(y_prueba, predictionsV2_test)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1_train.best_score_)\n",
    "print(\"Rendimiento de test V1:\", accuracyV1_test)\n",
    "\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2_train.best_score_)\n",
    "print(\"Rendimiento de test V2:\", accuracyV2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fcc9a6",
   "metadata": {},
   "source": [
    "### Modelo 9: Ensembles basados en descomposicion (OVO: One vs One)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d64176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Par치metros para la b칰squeda de la mejor configuraci칩n\n",
    "param_grid = {'estimator__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Creo el clasificador base (SVM)\n",
    "base_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Creo el modelo de OneVsOneClassifier con GridSearchCV para encontrar la mejor configuraci칩n\n",
    "ovo_clfV1 = OneVsOneClassifier(base_classifier)\n",
    "ovo_clfV2 = OneVsOneClassifier(base_classifier)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1_train = GridSearchCV(ovo_clfV1, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV1_train.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2_train = GridSearchCV(ovo_clfV2, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV2_train.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtengo el mejor clasificador\n",
    "best_clfV1_train = grid_searchV1_train.best_estimator_\n",
    "best_clfV2_train = grid_searchV2_train.best_estimator_\n",
    "\n",
    "# Realizo predicciones en el conjunto de prueba con los mejores clasficadores\n",
    "predictionsV1_test = best_clfV1_train.predict(X_pruebaV1)\n",
    "predictionsV2_test = best_clfV2_train.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "accuracyV1_test = accuracy_score(y_prueba, predictionsV1_test)\n",
    "accuracyV2_test = accuracy_score(y_prueba, predictionsV2_test)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Mejor configuraci칩n V1:\", grid_searchV1_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1_train.best_score_)\n",
    "print(\"Rendimiento de test V1:\", accuracyV1_test)\n",
    "\n",
    "print(\"Mejor configuraci칩n V2:\", grid_searchV2_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2_train.best_score_)\n",
    "print(\"Rendimiento de test V2:\", accuracyV2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3073b1",
   "metadata": {},
   "source": [
    "### Modelo 10: Ensembles basados en descomposicion (OVA: One vs All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97ae94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Par치metros para la b칰squeda de la mejor configuraci칩n\n",
    "param_grid = {'estimator__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Creo el clasificador base (SVM)\n",
    "base_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Creo el modelo de OneVsRestClassifier con GridSearchCV para encontrar la mejor configuraci칩n\n",
    "ova_clfV1 = OneVsRestClassifier(base_classifier)\n",
    "ova_clfV2 = OneVsRestClassifier(base_classifier)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V1\n",
    "grid_searchV1_train = GridSearchCV(ova_clfV1, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV1_train.fit(X_entrenamientoV1, y_entrenamiento)\n",
    "\n",
    "# Configuro la b칰squeda de par치metros con GridSearchCV para V2\n",
    "grid_searchV2_train = GridSearchCV(ova_clfV2, param_grid, cv=5, scoring='accuracy')\n",
    "grid_searchV2_train.fit(X_entrenamientoV2, y_entrenamiento)\n",
    "\n",
    "# Obtengo el mejor clasificador\n",
    "best_clfV1_train = grid_searchV1_train.best_estimator_\n",
    "best_clfV2_train = grid_searchV2_train.best_estimator_\n",
    "\n",
    "# Realizo predicciones en el conjunto de prueba con los mejores clasificadores\n",
    "predictionsV1_test = best_clfV1_train.predict(X_pruebaV1)\n",
    "predictionsV2_test = best_clfV2_train.predict(X_pruebaV2)\n",
    "\n",
    "# Calculo la precisi칩n de los clasificadores en los conjuntos de prueba\n",
    "accuracyV1_test = accuracy_score(y_prueba, predictionsV1_test)\n",
    "accuracyV2_test = accuracy_score(y_prueba, predictionsV2_test)\n",
    "\n",
    "# Imprimo el rendimiento en la validaci칩n cruzada y prueba\n",
    "print(\"Mejor configuraci칩n V1:\", grid_searchV1_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V1:\", grid_searchV1_train.best_score_)\n",
    "print(\"Rendimiento de test V1:\", accuracyV1_test)\n",
    "\n",
    "print(\"Mejor configuraci칩n V2:\", grid_searchV2_train.best_params_)\n",
    "print(\"Rendimiento de la validaci칩n cruzada V2:\", grid_searchV2_train.best_score_)\n",
    "print(\"Rendimiento de test V2:\", accuracyV2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acec6d0",
   "metadata": {},
   "source": [
    "# <font color='red'>6. Resultados/Comparacion de los algoritmos de extraccion y modelos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d33be",
   "metadata": {},
   "source": [
    "### Resultados de el algoritmo de extraccion de caracteristicas 1 (V1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d245051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Rendimiento de los modelos\n",
    "modelos = ['SVM', 'Regresion logistica', 'Regresion logistica polinomica', 'Redes neuronales',\n",
    "           'Bagging', 'Boosting', 'Random forest', 'Naive Bayes','OVO', 'OVA']\n",
    "rendimiento_validacion_cruzada = [0.6591666666666667, 0.6504166666666666, 0.6537499999999999, 0.6691666666666667, 0.6733333333333335, 0.45375000000000004, 0.6529166666666667, 0.5075000000000001, 0.6608333333333334, 0.63125]\n",
    "rendimiento_prueba = [0.5608333333333333, 0.5916666666666667, 0.5916666666666667, 0.6025, 0.5741666666666667, 0.3925, 0.5666666666666667,  0.5191666666666667, 0.55, 0.5733333333333334]\n",
    "\n",
    "# Creo un DataFrame con los datos\n",
    "data = pd.DataFrame({'Modelos': modelos, 'Rendimiento_validacion_cruzada': rendimiento_validacion_cruzada, 'Rendimiento_Prueba': rendimiento_prueba})\n",
    "\n",
    "# Gr치fico de barras con rendimiento de entrenamiento/validacion y prueba para cada modelo\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "data.plot(x='Modelos', y=['Rendimiento_validacion_cruzada', 'Rendimiento_Prueba'], kind='bar', ax=ax)\n",
    "plt.title('Rendimiento de Modelos para el algoritmo de extraccion de caracteristicas 1')\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Rendimiento')\n",
    "\n",
    "# Muevo la leyenda fuera del 치rea del gr치fico para que se vean los rendimientos\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# A침ado etiquetas de datos a las barras\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.4f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontsize=8)\n",
    "\n",
    "# Guardo la gr치fica como una imagen\n",
    "plt.savefig('rendimiento_modelosV1.png')\n",
    "\n",
    "# Muestro el gr치fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bea483",
   "metadata": {},
   "source": [
    "### Resultados de el algoritmo de extraccion de caracteristicas 2 (V2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806badbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendimiento de los modelos\n",
    "modelos = ['SVM', 'Regresion logistica', 'Regresion logistica polinomica', 'Redes neuronales',\n",
    "           'Bagging', 'Boosting', 'Random forest', 'Naive Bayes','OVO', 'OVA']\n",
    "rendimiento_validacion_cruzada = [0.7183333333333334, 0.7258333333333333, 0.7254166666666666, 0.7358333333333333, 0.7291666666666667, 0.5283333333333333, 0.7133333333333333, 0.6433333333333333, 0.7120833333333334, 0.705]\n",
    "rendimiento_prueba = [0.6341666666666667, 0.6408333333333334, 0.6408333333333334, 0.6358333333333334, 0.6308333333333334, 0.42333333333333334, 0.6475,  0.6583333333333333, 0.6366666666666667, 0.6141666666666666]\n",
    "\n",
    "# Creo un DataFrame con los datos\n",
    "data = pd.DataFrame({'Modelos': modelos, 'Rendimiento_validacion_cruzada': rendimiento_validacion_cruzada, 'Rendimiento_Prueba': rendimiento_prueba})\n",
    "\n",
    "# Gr치fico de barras con rendimiento de entrenamiento/validacion y prueba para cada modelo\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "data.plot(x='Modelos', y=['Rendimiento_validacion_cruzada', 'Rendimiento_Prueba'], kind='bar', ax=ax)\n",
    "plt.title('Rendimiento de Modelos para el algoritmo de extraccion de caracteristicas 2')\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('Rendimiento')\n",
    "\n",
    "# Muevo la leyenda fuera del 치rea del gr치fico para que se vean los rendimientos\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "\n",
    "# A침ado etiquetas de datos a las barras\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.4f}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points', fontsize=8)\n",
    "\n",
    "# Guardo la gr치fica como una imagen\n",
    "plt.savefig('rendimiento_modelosV2.png')\n",
    "\n",
    "# Muestro el gr치fico\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
